{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5349375a",
   "metadata": {},
   "source": [
    "# IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn\n",
    "from yellowbrick.model_selection import LearningCurve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import shap \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from pandas import DataFrame\n",
    "from numpy import matrix \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import joblib\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,accuracy_score,f1_score,recall_score,precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3b081d",
   "metadata": {},
   "source": [
    "# READ MATRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63a5850",
   "metadata": {},
   "source": [
    "Pearson's connection matrix of the EEG experiments of subjects who ingested Ayahuasca at the time after the psychedelic activation time can be found in: Alves, Caroline (2022): With-ayahuasca. figshare. Dataset. https://doi.org/10.6084/m9.figshare.21082513.v1\n",
    "\n",
    "Pearson's connection matrix of the EEG experiments of subjects who ingested Ayahuasca at the time before the psychedelic activation time: Alves, Caroline (2022): No-ayahuasca. figshare. Dataset.\n",
    "https://doi.org/10.6084/m9.figshare.21082531.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100fd7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define function to read\n",
    "def pixels_from_path(file_path):\n",
    "    im = open(file_path)\n",
    "    test = pd.read_csv(im,sep=\",\", index_col=False,header=None)\n",
    "    #im = im.resize(IMG_SIZE)\n",
    "    np_im = np.array(test)\n",
    "    #matrix of pixel RGB values\n",
    "    return np_im\n",
    "\n",
    "print(\"with ayahuasca\")\n",
    "#insert path for Pearson connectivity matrix with ayahuasca\n",
    "#aya = np.asarray([pixels_from_path(n) for n in glob.glob(r'PATH-ayahuasca-EEG-time-series/*csv')])\n",
    "aya = np.asarray([pixels_from_path(n) for n in glob.glob(r'connectivity-matrix/with-Ayahuasca/*csv')])\n",
    "print(\"shape for ayahuasca matrices\")\n",
    "print(np.shape(aya ))\n",
    "#insert path for Pearson connectivity matrix no ayahuasca\n",
    "print(\"no ayahuasca\")\n",
    "#normal = np.asarray([pixels_from_path(n) for n in glob.glob(r'PATH-no-ayahuasca-EEG-time-series/*csv')])\n",
    "normal = np.asarray([pixels_from_path(n) for n in glob.glob(r'connectivity-matrix/no-Ayahuasca/*csv')])\n",
    "#print(normal)\n",
    "print(\"shape for no ayahuasca matrices\")\n",
    "print(np.shape(normal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c0c48",
   "metadata": {},
   "source": [
    "# PREPARING TRAIN SET AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789ac953",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing train set\n",
    "scaler = StandardScaler()\n",
    "x = np.concatenate([normal ,aya])\n",
    "\n",
    "X= np.concatenate(x, axis=0)\n",
    "X=scaler.fit_transform(X)\n",
    "X=np.nan_to_num(X) \n",
    "print(\"shape for train set\")\n",
    "print(np.shape(X))\n",
    "## Preparing test set\n",
    "yes_l = [1]*len(np.concatenate(aya, axis=0))\n",
    "no_l = [0]*len(np.concatenate(normal, axis=0))\n",
    "labels = yes_l + no_l\n",
    "#print(labels) ## the labels of the graphs\n",
    "y=np.nan_to_num(labels)\n",
    "print(\"length for test set\")\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5a7004",
   "metadata": {},
   "source": [
    "# DEFINE MACHINE LEARNING MODEL, RESAMPLING AND GRID SEARCH TUNNING HYPERPARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92041c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.25)\n",
    "def get_mean_measures(model, X, y): \n",
    "    global param_grid\n",
    "    global model_est\n",
    "    #######\n",
    "    if model == 'RF':\n",
    "        param_grid = {\n",
    "            #'max_depth': [1,2,5,10,20,80],\n",
    "   # 'max_features': [1,2, 3,5,10],\n",
    "   # 'min_samples_leaf': [1,2,3, 4, 5],\n",
    "  #  'min_samples_split': [1,2,8, 10, 12,20],\n",
    "    'n_estimators': range(1, 50,2)\n",
    "    #'splitter':['best','random']\n",
    "  }\n",
    "        model_est= RandomForestClassifier(random_state=1234)\n",
    "    ########\n",
    "    elif model == 'SVM':\n",
    "        param_grid = {'C':range(1, 30)},\n",
    "        model_est= SVC(probability=True,random_state=1234)         \n",
    "    ########\n",
    "    elif model == 'NB':\n",
    "        param_grid=  {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "        model_est= GaussianNB()\n",
    "    \n",
    "    #########\n",
    "    elif model == 'MLP':\n",
    "        param_grid= {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)]}\n",
    "  #  'activation': ['tanh', 'relu'],\n",
    "   # 'solver': ['sgd', 'adam'],\n",
    "   # 'alpha': [0.0001, 0.05],\n",
    "   # 'learning_rate': ['constant','adaptive']}\n",
    "        model_est=MLPClassifier(random_state=1234)\n",
    "    #########\n",
    "    \n",
    "    elif model == 'KNN':\n",
    "        param_grid= {\n",
    "   # 'n_neighbors': (1,10, 1),\n",
    "    #'leaf_size': (20,40,1),\n",
    "    #'p': (1,2),\n",
    "    #'weights': ('uniform', 'distance'),\n",
    "    #'metric': ('minkowski', 'chebyshev') \n",
    "            'n_neighbors': range(1, 30)\n",
    "        }\n",
    "        model_est= KNeighborsClassifier()\n",
    "    #####\n",
    "    elif model == 'LR':\n",
    "        param_grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "        model_est= LogisticRegression(random_state=1234)\n",
    "    #####\n",
    "    elif model== 'XGboost':\n",
    "        param_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "        model_est= XGBClassifier(random_state=1234)\n",
    "    \n",
    "    ##########\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state = 1234) \n",
    "    recall = list()\n",
    "    precision = list()\n",
    "    f = list()\n",
    "    accuracy=list()\n",
    "    roc=list()\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "ps\n",
    "    for train_index, test_index in skf.split(X,y):\n",
    "        xtr, xvl = X.loc[train_index],X.loc[test_index]\n",
    "        ytr, yvl = y.loc[train_index],y.loc[test_index]\n",
    "\n",
    "        # Corrigindo o formato do ytr para ajustar o modelo\n",
    "        ytr = ytr.to_numpy()\n",
    "        ytr = ytr.reshape(len(ytr),)\n",
    "        \n",
    "        clf = GridSearchCV(model_est, param_grid, scoring='roc_auc')\n",
    "        clf.fit(xtr,ytr)\n",
    "        # Ajuste do modelo\n",
    "     #   model.fit(xtr,ytr)\n",
    "        clf_best= clf.best_estimator_\n",
    "        # predição\n",
    "        y_pred = clf.best_estimator_.predict(xvl)\n",
    "\n",
    "        # Corigindo o formato do yvl para poder calcular a acurácia\n",
    "        yvl = yvl.to_numpy()\n",
    "        yvl = yvl.reshape(len(yvl),)\n",
    "\n",
    "        # Calculando a acurácia, recall, precision, f1\n",
    "        roc.append(roc_auc_score(yvl,y_pred,average='weighted'))\n",
    "        accuracy.append(accuracy_score(yvl, y_pred))\n",
    "        recall.append(recall_score(yvl,y_pred,average='weighted'))\n",
    "        precision.append(precision_score(yvl,y_pred,average='weighted'))\n",
    "      #  print(f1_score(yvl,y_pred, average='weighted'))\n",
    "        f.append(sklearn.metrics.f1_score(yvl,y_pred,average='weighted'))\n",
    "        \n",
    "    return(roc,np.mean(roc), np.std(roc),        \n",
    "           accuracy,np.mean(accuracy), np.std(accuracy),\n",
    "           recall,np.mean(recall), np.std(recall),\n",
    "            precision,np.mean(precision), np.std(precision),\n",
    "           f,np.mean(f),np.std(f),\n",
    "           clf_best)\n",
    "    #return(np.mean(accuracy), np.mean(recall), np.mean(precision), np.mean(f),clf_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce03794",
   "metadata": {},
   "source": [
    "# RESAMPLING, CALLING THE MODEL AND PRINT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'RF'- Random forest model\n",
    "#'SVM'- Support Vector Machine model\n",
    "#'NB'- Naive Bayes model\n",
    "#'MLP'- Multilayer perceptron model\n",
    "#'KNN'- k-nearest neighbors model\n",
    "#'LR'- Logistic regression model\n",
    "#'XGboost'- Extreme Gradient Boosting classifier model\n",
    "\n",
    "roc,roc_mean, std_roc,acc,accuracy_mean, std_accuracy, rec,recall_mean, std_recall, pre,precision_mean,std_precision,f, f_mean, std_f, clf = get_mean_measures('SVM',X_train,y_train)\n",
    "\n",
    "results = { \n",
    "            'AUC': [roc_mean],\n",
    "            'Accuracy' : [accuracy_mean],\n",
    "            'Recall' : [recall_mean], \n",
    "            'Precision' : [precision_mean],\n",
    "            'f1-Score' : [f_mean]}\n",
    "df_results = pd.DataFrame(results)\n",
    "print('Train set preformance')\n",
    "print(df_results)\n",
    "\n",
    "print('Test set preformance')\n",
    "y_pred_test =  clf.predict(X_test)\n",
    "print('AUC test:',   roc_auc_score(y_test,y_pred_test))\n",
    "print('Accuracy test:', accuracy_score(y_test,y_pred_test))\n",
    "print('F1 score test:', f1_score(y_test,y_pred_test, average=\"macro\", pos_label=0))\n",
    "print('Recall test:', recall_score(y_test,y_pred_test,average=\"macro\", pos_label=0))\n",
    "print('Precision test:', precision_score(y_test,y_pred_test,average=\"macro\", pos_label=0))\n",
    "print(classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccdc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79490353",
   "metadata": {},
   "source": [
    "# PLOT CONFUSION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix')\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "cm_perc = cm / cm_sum.astype(float) * 100\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "nrows, ncols = cm.shape\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        c = cm[i, j]\n",
    "        p = cm_perc[i, j]\n",
    "        if i == j:\n",
    "            s = cm_sum[i]\n",
    "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "        elif c == 0:\n",
    "            annot[i, j] = ''\n",
    "        else:\n",
    "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "cm = pd.DataFrame(cm)\n",
    "   # print(cm)\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "#fig, ax = plt.subplots(figsize=figsize)\n",
    "sns.heatmap(cm, annot=annot, fmt='',cmap='rocket_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ec9fbf",
   "metadata": {},
   "source": [
    "# PLOT ROC CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d27461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Roc curve')\n",
    "n_classes =2\n",
    "\n",
    "t1=sum(x==0 for x in y_pred_test-y_test)/len(y_pred_test)\n",
    "\n",
    "    ### MACRO\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(np.array(pd.get_dummies(y_test))[:, i], np.array(pd.get_dummies(y_pred_test))[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "lw=2\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='slategray', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['purple', 'lightseagreen'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0}'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--',color='#cb416b', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.annotate(' Random Guess',(.5,.48),color='#cb416b')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "#plt.title('Receiver Operating Characteristic for Suport Vector Machine')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig(\"ROC-svm-measures.pdf\",dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72d1af",
   "metadata": {},
   "source": [
    "# PLOT LEARNING CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12870e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.linspace(0.3, 1.0, 10)\n",
    "#best= clf.best_estimator_\n",
    "visualizer = LearningCurve(\n",
    "   clf, cv=10, scoring='accuracy', train_sizes=sizes, n_jobs=4\n",
    ")\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Fit the data to the visualizer\n",
    "visualizer.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3376538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
